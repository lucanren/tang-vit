
model BASELINE
5x5 of 10x10, straight to mlp, no transformer 
0.083 (yes pos embed) - model 0
0.06 (no pos embed)

model BASELINE 
10x10 of 5x5, straight to mlp, no transformer 
0.06 (yes pos embed)
0.07 (no pos embed)

model 1
10x10 of 5x5, 2 heads, 2 transformer blocks, hidden d = 12
0.21 on neuron 1 m1s1

model 2
10x10 of 5x5, 2 heads, 2 transformer blocks, hidden d = 12
0.3 on neuron 1 m1s1
0.29 with class token removes

model 3
10x10 of 5x5, 1 heads, 1 transformer blocks, hidden d = 12, removed class token
0.17 - 0.2

model 4
5x5 of 10x10, 1 heads, 1 transformer blocks, hidden d = 12, removed class token
0.25

model 5
5x5 of 10x10, 2 heads, 1 transformer blocks, hidden d = 12, removed class token
0.16

model 6
5x5 of 10x10, 2 heads, 2 transformer blocks, hidden d = 12, removed class token
0.29

model 7
5x5 of 10x10, 1 heads, 4 transformer blocks, hidden d = 12, removed class token
0.26

model 8
10x10 of 5x5, 1 heads, 4 transformer blocks, hidden d = 12, removed class token
0.24

model 9
10x10 of 5x5, 2 heads, 4 transformer blocks, hidden d = 12, removed class token
0.33

model 10
5x5 of 10x10, 2 heads, 4 transformer blocks, hidden d = 12, removed class token
0.27

model 11
25x25 of 2x2, 2 heads, 2 transformer blocks, hidden d = 12, removed class token
0.07

model 12
2x2 of 25x25, 2 heads, 2 transformer blocks, hidden d = 12, removed class token
0.17s

model 13
10x10 of 5x5, 1 heads, 1 transformer blocks, hidden d = 200, removed class token
0.11

